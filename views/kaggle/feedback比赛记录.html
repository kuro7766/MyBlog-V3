<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>FeedBack比赛记录 | Kuro&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/MyBlog-V3/favicon.svg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <meta name="description" content="现居住于猎户臂上的一个碳基生命">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/MyBlog-V3/assets/css/0.styles.55a4f562.css" as="style"><link rel="preload" href="/MyBlog-V3/assets/js/app.2fcf86d5.js" as="script"><link rel="preload" href="/MyBlog-V3/assets/js/4.6a1bbe31.js" as="script"><link rel="preload" href="/MyBlog-V3/assets/js/1.3d31ad93.js" as="script"><link rel="preload" href="/MyBlog-V3/assets/js/15.cd5d72a6.js" as="script"><link rel="prefetch" href="/MyBlog-V3/assets/js/10.99cfe6d9.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/11.3482dd79.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/12.0c244f9a.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/13.2a02a67a.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/14.9db22699.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/16.4121853c.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/17.b29a0c97.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/18.37f03248.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/19.6eb4fce7.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/2.33003707.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/20.a2b93281.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/21.54643684.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/5.6bbefc0d.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/6.16f2cb69.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/7.66c655da.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/8.8db90568.js"><link rel="prefetch" href="/MyBlog-V3/assets/js/9.4e1962b7.js">
    <link rel="stylesheet" href="/MyBlog-V3/assets/css/0.styles.55a4f562.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-130b300a><div data-v-130b300a><div class="password-shadow password-wrapper-out" style="display:none;" data-v-25ba6db2 data-v-130b300a data-v-130b300a><h3 class="title" data-v-25ba6db2 data-v-25ba6db2>Kuro's Blog</h3> <p class="description" data-v-25ba6db2 data-v-25ba6db2>现居住于猎户臂上的一个碳基生命</p> <label id="box" class="inputBox" data-v-25ba6db2 data-v-25ba6db2><input type="password" value="" data-v-25ba6db2> <span data-v-25ba6db2>Konck! Knock!</span> <button data-v-25ba6db2>OK</button></label> <div class="footer" data-v-25ba6db2 data-v-25ba6db2><span data-v-25ba6db2><i class="iconfont reco-theme" data-v-25ba6db2></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-25ba6db2>vuePress-theme-reco</a></span> <span data-v-25ba6db2><i class="iconfont reco-copyright" data-v-25ba6db2></i> <a data-v-25ba6db2><span data-v-25ba6db2>kuro</span>
            
          <span data-v-25ba6db2>2020 - </span>
          2022
        </a></span></div></div> <div class="hide" data-v-130b300a><header class="navbar" data-v-130b300a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/MyBlog-V3/" class="home-link router-link-active"><!----> <span class="site-name">Kuro's Blog</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/MyBlog-V3/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/MyBlog-V3/categories/kaggle/" class="nav-link"><i class="undefined"></i>
  kaggle
</a></li><li class="dropdown-item"><!----> <a href="/MyBlog-V3/categories/leetcode/" class="nav-link"><i class="undefined"></i>
  leetcode
</a></li><li class="dropdown-item"><!----> <a href="/MyBlog-V3/categories/MCU/" class="nav-link"><i class="undefined"></i>
  MCU
</a></li></ul></div></div><div class="nav-item"><a href="/MyBlog-V3/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-api"></i>
      工具
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="http://clouddisk.tsanfer.com:8080" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="fa fa-hdd"></i>
  网盘
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      联系
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/kuro7766" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-130b300a></div> <aside class="sidebar" data-v-130b300a><div class="personal-info-wrapper" data-v-39576ba9 data-v-130b300a><img src="/MyBlog-V3/avatar.svg" alt="author-avatar" class="personal-img" data-v-39576ba9> <h3 class="name" data-v-39576ba9>
    kuro
  </h3> <div class="num" data-v-39576ba9><div data-v-39576ba9><h3 data-v-39576ba9>8</h3> <h6 data-v-39576ba9>Articles</h6></div> <div data-v-39576ba9><h3 data-v-39576ba9>7</h3> <h6 data-v-39576ba9>Tags</h6></div></div> <ul class="social-links" data-v-39576ba9><li class="social-item" data-v-39576ba9><i class="iconfont reco-github" style="color:#f8b26a;" data-v-39576ba9></i></li><li class="social-item" data-v-39576ba9><i class="iconfont reco-qq" style="color:#f47e60;" data-v-39576ba9></i></li></ul> <hr data-v-39576ba9></div> <nav class="nav-links"><div class="nav-item"><a href="/MyBlog-V3/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/MyBlog-V3/categories/kaggle/" class="nav-link"><i class="undefined"></i>
  kaggle
</a></li><li class="dropdown-item"><!----> <a href="/MyBlog-V3/categories/leetcode/" class="nav-link"><i class="undefined"></i>
  leetcode
</a></li><li class="dropdown-item"><!----> <a href="/MyBlog-V3/categories/MCU/" class="nav-link"><i class="undefined"></i>
  MCU
</a></li></ul></div></div><div class="nav-item"><a href="/MyBlog-V3/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-api"></i>
      工具
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="http://clouddisk.tsanfer.com:8080" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="fa fa-hdd"></i>
  网盘
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      联系
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/kuro7766" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Kaggle比赛</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/MyBlog-V3/views/kaggle/Kaggle中总结的常用的调试脚本.html" class="sidebar-link">Kaggle中常用的调试脚本</a></li><li><a href="/MyBlog-V3/views/kaggle/Kaggle-OpenProblem.html" class="sidebar-link">Kaggle-OpenProblem</a></li><li><a href="/MyBlog-V3/views/kaggle/patent_phrase.html" class="sidebar-link">PatentPhrase比赛记录</a></li><li><a href="/MyBlog-V3/views/kaggle/feedback比赛记录.html" class="active sidebar-link">FeedBack比赛记录</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-25ba6db2 data-v-130b300a><h3 class="title" data-v-25ba6db2 data-v-25ba6db2>FeedBack比赛记录</h3> <!----> <label id="box" class="inputBox" data-v-25ba6db2 data-v-25ba6db2><input type="password" value="" data-v-25ba6db2> <span data-v-25ba6db2>Konck! Knock!</span> <button data-v-25ba6db2>OK</button></label> <div class="footer" data-v-25ba6db2 data-v-25ba6db2><span data-v-25ba6db2><i class="iconfont reco-theme" data-v-25ba6db2></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-25ba6db2>vuePress-theme-reco</a></span> <span data-v-25ba6db2><i class="iconfont reco-copyright" data-v-25ba6db2></i> <a data-v-25ba6db2><span data-v-25ba6db2>kuro</span>
            
          <span data-v-25ba6db2>2020 - </span>
          2022
        </a></span></div></div> <div data-v-130b300a><main class="page"><section><div class="page-title"><h1 class="title">FeedBack比赛记录</h1> <div data-v-f875f3fc><i class="iconfont reco-account" data-v-f875f3fc><span data-v-f875f3fc>kuro</span></i> <i class="iconfont reco-date" data-v-f875f3fc><span data-v-f875f3fc>8/3/2022</span></i> <!----> <i class="tags iconfont reco-tag" data-v-f875f3fc><span class="tag-item" data-v-f875f3fc>kaggle</span></i></div></div> <div class="theme-reco-content content__default"><hr> <p><a href="https://www.kaggle.com/competitions/feedback-prize-effectiveness" target="_blank" rel="noopener noreferrer">Feedback Prize - Predicting Effective Arguments<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <div class="spinner" style="background:rgb(66, 185, 131);" data-v-1bbcb91a></div><p>因为我手里卡不多，只能冻结一部分。</p> <p><img src="http://kuroweb.tk/picture/16591075317336250.jpg" alt=""></p> <p>不加预训练的模型都要差。其中两层的模型和4层的模型效果差不多。</p> <ul><li>v39-shuffle_nopreload: 无预训练模型</li> <li>v46：无预训练模型，仅训练后2层</li> <li>v39-shuffle_nopreload: 预训练模型</li></ul> <hr> <p><img src="http://kuroweb.tk/picture/16591073049762930.jpg" alt=""></p> <p>所以后续的尝试在预训练模型上面，在cls上做分类，因为与训练任务的特性。预训练有两个任务，一个是判断两段文本是否连接，一个是mlm。CLS位置为了捕获两段文本的上下文信息，需要有全局的关注力。而每个位置的token经过bert最终得到的输出可以看成是某种embedding，适合做token ner任务。</p> <p><img src="http://kuroweb.tk/picture/16591075317336250.jpg" alt=""></p> <hr> <h2 id="模型学习了什么"><a href="#模型学习了什么" class="header-anchor">#</a> 模型学习了什么</h2> <hr> <h3 id="打分可视化"><a href="#打分可视化" class="header-anchor">#</a> 打分可视化</h3> <p>我在榜单上找到了一个高分的笔记本。使用前端界面把打分<a href="https://kuro7766.github.io/FeedbackEda/build/web/" target="_blank" rel="noopener noreferrer">可视化<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>后，可以发现两个重要的事实。</p> <ul><li>1.全文的分数几乎都一样</li> <li>2.个别分数与全文分数不同的部分，置信度全都比较低。</li></ul> <p>第1点正如deberta v3 large1024的效果相符合，更长的的句子长度可以帮助模型捕获整篇文章的信息。</p> <p>第2点是难以学习的，因为这部分句子往往不超过整个句子的10%，模型难以关注这部分。如何才能让模型更好的关注到这部分的信息？</p> <hr> <h2 id="baseline-improve"><a href="#baseline-improve" class="header-anchor">#</a> baseline &amp; improve</h2> <h3 id="baseline"><a href="#baseline" class="header-anchor">#</a> baseline</h3> <p>CV大概在0.6左右，由于是 straight K fold，所以每个fold的CV差不多。</p> <p>找到了一个别人的base，运行了两遍，分数几乎一样</p> <p><img src="http://kuroweb.tk/picture/16594198833918976.jpg" alt=""></p> <p>后续的模型改进都和这个曲线做对比。</p> <hr> <h3 id="baseline后两层相加"><a href="#baseline后两层相加" class="header-anchor">#</a> baseline后两层相加</h3> <p><img src="http://kuroweb.tk/picture/16622917010122740.png" alt=""></p> <p>把bert最后两层直接加起来，可以实现更好的效果，低了0.004，当然也可能是抖动随机的效果。为了探究其中的原因，我们来看一下train loss。</p> <p><img src="http://kuroweb.tk/picture/16595254938246282.jpg" alt=""></p> <p>我们以后半部分作为观察对象，可见在绝大部分的位置上，后两层相加的模型的loss显然更优，这也说明网络在这样的结构下，更容易找到梯度。因此后续的工作应该集中在如何找到更快下降的loss上，如果发现loss明显下降的更快，则有更大的概率是eval也更优的模型。</p> <hr> <h3 id="后两层-1个可学习权重"><a href="#后两层-1个可学习权重" class="header-anchor">#</a> <a name="1"></a> 后两层+1个可学习权重</h3> <p><img src="http://kuroweb.tk/picture/16595367798825914.jpg" alt=""></p> <p>和baseline模型相比。后两层相加得到了更好的效果。实现了在早期的时间达到了一个最低的loss。0.4492优于之前的0.4574，是一个比较明显的提升，可见模型的收敛较快。</p> <p><img src="http://kuroweb.tk/picture/16595371488447532.jpg" alt=""></p> <p>同时eval loss 也在第三个epoch的时候达到了和 Baseline模型相持平的水平，后续改进有较大的可能性。</p> <h3 id="后两层两个动态权重"><a href="#后两层两个动态权重" class="header-anchor">#</a> 后两层两个动态权重</h3> <p><img src="http://kuroweb.tk/picture/16595443671352084.png" alt=""></p> <p>非常有效，train loss达到了0.43，在3.26 epoch，降低了0.02，前所未有的低</p> <p>由于eval的频次有点低，导致最低点处没有eval，所以没有体现出来。这里显示的是动态权重不如baseline。</p> <p><img src="http://kuroweb.tk/picture/16595444895616866.png" alt=""></p> <p>所以这个方法和<a href="#1">后两层+1个可学习权重</a>都需要设置eval为3 or 4/per epoch左右才可以显示出来效果</p> <p>经过修改eval per epoch为4后，可见确实出现了更优的结果</p> <p><img src="http://kuroweb.tk/picture/16596026399109478.png" alt=""></p> <p>在2.25 epoch出现了best loss</p> <p>best eval loss: <strong>0.5958 -&gt; 0.5857</strong></p> <p><img src="http://kuroweb.tk/picture/16596030745607114.png" alt=""></p> <p>意外的是，最优的eval loss不是在train loss 3.25 epoch最低点这里出现的，而是在2.25，出现的更早了。但这也不是坏事，说明模型有非常快的收敛速度。</p> <p>同样的我把baseline也调整为4 eval per epoch</p> <h3 id="添加外部数据和特征"><a href="#添加外部数据和特征" class="header-anchor">#</a> 添加外部数据和特征</h3> <p>仿照<a href="https://www.kaggle.com/competitions/feedback-prize-effectiveness/discussion/333277" target="_blank" rel="noopener noreferrer">bert topic<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的思路，我添加了另一个模型。</p> <p>基于<a href="https://www.phrasebank.manchester.ac.uk/" target="_blank" rel="noopener noreferrer">phrasebank数据集<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的分类模型，该数据集质量比较高，并且和写作的相关性比较大，我们可以提取它的分类前的logits作为本任务的预处理特征</p> <p><img src="http://kuroweb.tk/picture/16602927485311630.jpg" alt=""></p> <p>v29在v19（baseline）上面有了小幅度的提升，效果和berttopic类似。可见，添加和数据集相关的数据是比较稳定的上分方法。根据No free lunch theory，没有一种在任何任务上表现的都很好的模型。</p> <h2 id="其他尝试"><a href="#其他尝试" class="header-anchor">#</a> 其他尝试</h2> <h3 id="deberta-base-512"><a href="#deberta-base-512" class="header-anchor">#</a> deberta base 512</h3> <p>似乎不work</p> <p>长度增长可见有明显的问题，很可能是淹没了短句子的效果。</p> <p>loss图像，train loss偏高，且更早的达到了过拟合。。</p> <p><img src="http://kuroweb.tk/picture/16595261404163210.jpg" alt=""></p> <h3 id="deberta-large-384"><a href="#deberta-large-384" class="header-anchor">#</a> deberta large 384</h3> <p>没有得到更好的效果，loss下降变得困难，可能是因为搜索空间太大了。</p> <p>训练loss偏高，甚至和上面的base512也有一定的差距。且过拟合发生的时间较早。猜测模型可能关注更深的信息，而针对本数据集没有那么多的信息要学习。</p> <p><img src="http://kuroweb.tk/picture/16595262821585440.jpg" alt=""></p> <h3 id="deberta-base-360"><a href="#deberta-base-360" class="header-anchor">#</a> deberta base 360</h3> <p>两者几乎持平，说明长度变少并未变弱模型的效果。后面可以进一步尝试，继续减少长度。</p> <p><img src="http://kuroweb.tk/picture/16595267143843442.jpg" alt=""></p> <p>eval loss最优大概减少了0.0003个点，继续来看一下train loss后半段</p> <p><img src="http://kuroweb.tk/picture/16595274436582224.jpg" alt=""></p> <p>max_len 360的train loss最低点比baseline更优，同时最优eval loss也是在这个点左右完成的。可见模型train loss下降的越快、更低，越能找到更真正的东西。train loss和eval loss是一致的</p> <p>可参考的最优loss为 <strong>0.456~0.457</strong></p> <h3 id="最后三层相加"><a href="#最后三层相加" class="header-anchor">#</a> 最后三层相加</h3> <ul><li>1.求平均</li></ul> <p>这种办法效果会变得特别差，效果不好。</p> <ul><li>2.直接相加，但是权重等于变成了三倍</li></ul> <p>同样的来看train loss后半段。</p> <p><img src="http://kuroweb.tk/picture/16595288088231332.jpg" alt=""></p> <p>后三层相加的结果要稍微的差一些。与最后两层直接相加相比，没有达到更好的效果。可见，适合本数据集的层数大概在一层上下的差距。</p> <p>同时，1）和2）相差悬殊，这让我想到了另一个提高模型的点的办法，那就是给后两层相加的模型添加一个可学习的权重。</p> <h3 id="top-layer-reinitialization"><a href="#top-layer-reinitialization" class="header-anchor">#</a> top layer reinitialization</h3> <p>因为语言模型的浅层保存的是通用的特征，靠近输出的地方是更加 task specific特征。之前的mlm任务保留的权重可能会对当前任务造成一些的限制</p> <p><img src="http://kuroweb.tk/picture/16597132571626208.png" alt=""></p> <p>但是运行之后发现这么做反而是最差的，如图中v16两个曲线（红蓝），在所有曲线的最上层</p> <h3 id="加入人工抽取的关键词"><a href="#加入人工抽取的关键词" class="header-anchor">#</a> 加入人工抽取的关键词</h3> <p>有略微的提升，当然也可能是偶然出现的，提升不大。如果能像上次patent针对每个类别加入动态的文本比较好</p> <p><img src="http://kuroweb.tk/picture/16597140998333988.jpg" alt=""></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>you your they we i think but also these some many people because there are
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>是我认为写的比较差的作文里常用的词汇。经尝试提升不明显。</p> <h3 id="textcnn"><a href="#textcnn" class="header-anchor">#</a> TextCNN</h3> <p>闲暇时间的翻阅之后，我发现比较差的文章比较喜欢用一些短语。</p> <p>对于短语的提取可以使用text Cnn来实现，在bert的最后一层加上。</p> <p>那么是加全局还是仅在ShortSentence呢？可能各有优势</p> <ul><li><p>1.全局：增加文章整体分数判断的能力。但是局部分类可能不行。</p></li> <li><p>2.ShortSentence</p> <p>本次的任务是段文本分类，长文本作为上下文来使用。由于bert是微调的，输出位置的短文本位置保留了短文本这部分的信息，如果短文本需要一些额外信息，他可以自己去长文本里查询——如果这一点成立，那么不一定需要用text CNN，作用在局部的mean pooling也可以试一试。</p></li></ul> <p><img src="http://kuroweb.tk/picture/16591082895515714.jpg" alt=""></p> <h4 id="部分作用的cnn技术上的实现"><a href="#部分作用的cnn技术上的实现" class="header-anchor">#</a> 部分作用的cnn技术上的实现</h4> <p>为了验证上述的想法，自然是需要做实验，一个个尝试。</p> <p>在预处理的时候计算mask，然后直接mask_fill作用于最后一层</p> <p><img src="http://kuroweb.tk/picture/16591089156903596.jpg" alt=""></p> <p>经过尝试，效果不佳。</p> <h3 id="longformer相关的尝试"><a href="#longformer相关的尝试" class="header-anchor">#</a> Longformer相关的尝试</h3> <p>因为比赛的举办方曾经用这次比赛数据集的另一部分举办过一次比赛。并且在那次比赛中longformer是sota，所以我在这里尝试但是似乎并不适合。</p> <h4 id="把作文尾句放在前面"><a href="#把作文尾句放在前面" class="header-anchor">#</a> 把作文尾句放在前面</h4> <p>大家都知道写作的时候，作文的尾句是比较重要的东西，一般都是总结文章重新重申主题，并且语言通常是比较干净的。</p> <p><img src="http://kuroweb.tk/picture/16602940912477520.jpg" alt=""></p> <p>cv在0.76</p> <h4 id="浅层隐藏层权重"><a href="#浅层隐藏层权重" class="header-anchor">#</a> 浅层隐藏层权重</h4> <p>语言模型的浅层保存的是通用的特征，深层是更加抽象的特征，但是如果数据的量不够，深层的模型反而对训练会造成阻碍。</p> <p>已知 deberta base-&gt;deberta large 会 cv+0.02，但是从12层-&gt;25层这样粗暴的调整它，肯定还有某些层是更优的，就是这样的调参是非常粗略的。关于模型的深浅度只有两种情况，一种是模型太深，一种是太浅。</p> <p>太浅的解决办法就是向后面添加更多的层，fcl，rnn，attention均可。剩下的部分就是世界当前算力的限制，大部分人都难以突破。</p> <p>太深的解决办法，就是只看某浅层hidden layer的输出，在梯度下降的时候忽视深层网络里面的输出，阻止其梯度下降。因为我们知道在数据的分布比较简单的数据集中，如果用太深的网络，反而会导致收敛慢精度低的问题，浅层的神经网络在此方面反而表现的更好。</p> <p>让NLP深度模型变浅有几种办法：</p> <p>1.冻结前几层</p> <p>2.丢弃后几层</p> <p>但是这个几层是怎么确定的呢？如果不断的调参是非常麻烦的。可以给每个隐藏层加权加起来，作为最后的隐藏层输出，模型梯度下降会自己去找，下降速度最快的那一层。</p> <p>实验证明，这样效果不错，是比较通用且稳定的上分办法。</p> <h4 id="attention-pooling"><a href="#attention-pooling" class="header-anchor">#</a> Attention Pooling</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">AttentionHead</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">768</span><span class="token punctuation">,</span> hidden_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">512</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AttentionHead<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>V <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        att <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>V<span class="token punctuation">(</span>att<span class="token punctuation">)</span>
        <span class="token comment"># sdb(score)</span>
        <span class="token comment"># adb(score)</span>
        attention_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># adb(attention_weights)</span>
        <span class="token comment"># sdb(features)</span>
        context_vector <span class="token operator">=</span> attention_weights <span class="token operator">*</span> features
        context_vector <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>context_vector<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>context_vector<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p>attention pooling 可以作为一种选择，和cnn、lstm、meanpooling类似。</p> <h4 id="冻结-多层lstm-pooling"><a href="#冻结-多层lstm-pooling" class="header-anchor">#</a> 冻结+多层lstm pooling</h4> <p>❌效果很差</p> <h4 id="shuffle-vs-order"><a href="#shuffle-vs-order" class="header-anchor">#</a> Shuffle vs Order</h4> <p>经过<a href="https://kuro7766.github.io/FeedbackEda/build/web/" target="_blank" rel="noopener noreferrer">EDA<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>观察，我发现同一篇文章中，那些得分和本文大部分评分不一样的地方，比如说全文都是effective，只有一个句子是ineffective，那么这个句子打分的置信度会非常低。经过观察这是非常普遍的现象。可以尝试一下用一个单独的分类器来分类是否为置信度低的样本，然后把logits送给fcl。</p> <h3 id="其他还未尝试想法"><a href="#其他还未尝试想法" class="header-anchor">#</a> 其他还未尝试想法</h3> <p>加入ML book的特征</p> <p>加外部数据</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">最后更新时间: </span> <span class="time">9/9/2022, 7:29:31 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/MyBlog-V3/views/kaggle/patent_phrase.html" class="prev">
            PatentPhrase比赛记录
          </a></span> <!----></p></div> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-cb1513f6><li class="level-2" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#模型学习了什么" class="sidebar-link reco-side-模型学习了什么" data-v-cb1513f6>模型学习了什么</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#打分可视化" class="sidebar-link reco-side-打分可视化" data-v-cb1513f6>打分可视化</a></li><li class="level-2" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#baseline-improve" class="sidebar-link reco-side-baseline-improve" data-v-cb1513f6>baseline &amp; improve</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#baseline" class="sidebar-link reco-side-baseline" data-v-cb1513f6>baseline</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#baseline后两层相加" class="sidebar-link reco-side-baseline后两层相加" data-v-cb1513f6>baseline后两层相加</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#后两层-1个可学习权重" class="sidebar-link reco-side-后两层-1个可学习权重" data-v-cb1513f6>后两层+1个可学习权重</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#后两层两个动态权重" class="sidebar-link reco-side-后两层两个动态权重" data-v-cb1513f6>后两层两个动态权重</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#添加外部数据和特征" class="sidebar-link reco-side-添加外部数据和特征" data-v-cb1513f6>添加外部数据和特征</a></li><li class="level-2" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#其他尝试" class="sidebar-link reco-side-其他尝试" data-v-cb1513f6>其他尝试</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#deberta-base-512" class="sidebar-link reco-side-deberta-base-512" data-v-cb1513f6>deberta base 512</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#deberta-large-384" class="sidebar-link reco-side-deberta-large-384" data-v-cb1513f6>deberta large 384</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#deberta-base-360" class="sidebar-link reco-side-deberta-base-360" data-v-cb1513f6>deberta base 360</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#最后三层相加" class="sidebar-link reco-side-最后三层相加" data-v-cb1513f6>最后三层相加</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#top-layer-reinitialization" class="sidebar-link reco-side-top-layer-reinitialization" data-v-cb1513f6>top layer reinitialization</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#加入人工抽取的关键词" class="sidebar-link reco-side-加入人工抽取的关键词" data-v-cb1513f6>加入人工抽取的关键词</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#textcnn" class="sidebar-link reco-side-textcnn" data-v-cb1513f6>TextCNN</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#longformer相关的尝试" class="sidebar-link reco-side-longformer相关的尝试" data-v-cb1513f6>Longformer相关的尝试</a></li><li class="level-3" data-v-cb1513f6><a href="/MyBlog-V3/views/kaggle/feedback%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95.html#其他还未尝试想法" class="sidebar-link reco-side-其他还未尝试想法" data-v-cb1513f6>其他还未尝试想法</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><APlayer audio="" fixed="true" theme="#3489fd" loop="loop" order="list" preload="auto" volume="0.7" mutex="true" lrc-type="3" list-max-height="250" storage-name="vuepress-plugin-meting" id="aplayer-fixed"></APlayer><!----></div></div>
    <script src="/MyBlog-V3/assets/js/app.2fcf86d5.js" defer></script><script src="/MyBlog-V3/assets/js/4.6a1bbe31.js" defer></script><script src="/MyBlog-V3/assets/js/1.3d31ad93.js" defer></script><script src="/MyBlog-V3/assets/js/15.cd5d72a6.js" defer></script>
  </body>
</html>
