(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{715:function(t,e,a){"use strict";a.r(e);var r=a(7),s=Object(r.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[a("a",{attrs:{href:"https://www.kaggle.com/competitions/feedback-prize-effectiveness",target:"_blank",rel:"noopener noreferrer"}},[t._v("Feedback Prize - Predicting Effective Arguments"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("因为我手里卡不多，只能冻结一部分。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16591075317336250.jpg",alt:""}})]),t._v(" "),a("p",[t._v("不加预训练的模型都要差。其中两层的模型和4层的模型效果差不多。")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("v39-shuffle_nopreload: 无预训练模型")])]),t._v(" "),a("li",[a("p",[t._v("v46：无预训练模型，仅训练后2层")])]),t._v(" "),a("li",[a("p",[t._v("v39-shuffle_nopreload: 预训练模型")])])]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16591073049762930.jpg",alt:""}})]),t._v(" "),a("p",[t._v("所以后续的尝试在预训练模型上面，在cls上做分类，因为与训练任务的特性。预训练有两个任务，一个是判断两段文本是否连接，一个是mlm。CLS位置为了捕获两段文本的上下文信息，需要有全局的关注力。而每个位置的token经过bert最终得到的输出可以看成是某种embedding，适合做token ner任务。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16591075317336250.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"模型学习了什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模型学习了什么"}},[t._v("#")]),t._v(" 模型学习了什么")]),t._v(" "),a("h3",{attrs:{id:"打分可视化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#打分可视化"}},[t._v("#")]),t._v(" 打分可视化")]),t._v(" "),a("p",[t._v("我在榜单上找到了一个高分的笔记本。使用前端界面把打分"),a("a",{attrs:{href:"https://kuro7766.github.io/FeedbackEda/build/web/",target:"_blank",rel:"noopener noreferrer"}},[t._v("可视化"),a("OutboundLink")],1),t._v("后，可以发现两个重要的事实。")]),t._v(" "),a("ul",[a("li",[t._v("1.全文的分数几乎都一样")]),t._v(" "),a("li",[t._v("2.个别分数与全文分数不同的部分，置信度全都比较低。")])]),t._v(" "),a("p",[t._v("第1点正如deberta v3 large1024的效果相符合，更长的的句子长度可以帮助模型捕获整篇文章的信息。")]),t._v(" "),a("p",[t._v("第2点是难以学习的，因为这部分句子往往不超过整个句子的10%，模型难以关注这部分。如何才能让模型更好的关注到这部分的信息？")]),t._v(" "),a("h2",{attrs:{id:"baseline-improve"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#baseline-improve"}},[t._v("#")]),t._v(" baseline & improve")]),t._v(" "),a("h3",{attrs:{id:"baseline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#baseline"}},[t._v("#")]),t._v(" baseline")]),t._v(" "),a("p",[t._v("CV大概在0.6左右，由于是 straight K fold，所以每个fold的CV差不多。")]),t._v(" "),a("p",[t._v("找到了一个别人的base，运行了两遍，分数几乎一样")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16594198833918976.jpg",alt:""}})]),t._v(" "),a("p",[t._v("后续的模型改进都和这个曲线做对比。")]),t._v(" "),a("h3",{attrs:{id:"baseline后两层相加"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#baseline后两层相加"}},[t._v("#")]),t._v(" baseline后两层相加")]),t._v(" "),a("p",[a("img",{attrs:{src:"C:%5CUsers%5C1%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220803191354913.png",alt:""}})]),t._v(" "),a("p",[t._v("把bert最后两层直接加起来，可以实现更好的效果，低了0.004，当然也可能是抖动随机的效果。为了探究其中的原因，我们来看一下train loss。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595254938246282.jpg",alt:""}})]),t._v(" "),a("p",[t._v("我们以后半部分作为观察对象，可见在绝大部分的位置上，后两层相加的模型的loss显然更优，这也说明网络在这样的结构下，更容易找到梯度。因此后续的工作应该集中在如何找到更快下降的loss上，如果发现loss明显下降的更快，则有更大的概率是eval也更优的模型。")]),t._v(" "),a("h3",{attrs:{id:"后两层-1个可学习权重"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#后两层-1个可学习权重"}},[t._v("#")]),t._v(" "),a("a",{attrs:{name:"1"}}),t._v(" 后两层+1个可学习权重")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595367798825914.jpg",alt:""}})]),t._v(" "),a("p",[t._v("和baseline模型相比。后两层相加得到了更好的效果。实现了在早期的时间达到了一个最低的loss。0.4492优于之前的0.4574，是一个比较明显的提升，可见模型的收敛较快。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595371488447532.jpg",alt:""}})]),t._v(" "),a("p",[t._v("同时eval loss 也在第三个epoch的时候达到了和 Baseline模型相持平的水平，后续改进有较大的可能性。")]),t._v(" "),a("h3",{attrs:{id:"后两层两个动态权重"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#后两层两个动态权重"}},[t._v("#")]),t._v(" 后两层两个动态权重")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595443671352084.png",alt:""}})]),t._v(" "),a("p",[t._v("非常有效，train loss达到了0.43，在3.26 epoch，降低了0.02，前所未有的低")]),t._v(" "),a("p",[t._v("由于eval的频次有点低，导致最低点处没有eval，所以没有体现出来。这里显示的是动态权重不如baseline。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595444895616866.png",alt:""}})]),t._v(" "),a("p",[t._v("所以这个方法和"),a("a",{attrs:{href:"#1"}},[t._v("后两层+1个可学习权重")]),t._v("都需要设置eval为3 or 4/per epoch左右才可以显示出来效果")]),t._v(" "),a("p",[t._v("经过修改eval per epoch为4后，可见确实出现了更优的结果")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16596026399109478.png",alt:""}})]),t._v(" "),a("p",[t._v("在2.25 epoch出现了best loss")]),t._v(" "),a("p",[t._v("best eval loss: "),a("strong",[t._v("0.5958 -> 0.5857")])]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16596030745607114.png",alt:""}})]),t._v(" "),a("p",[t._v("意外的是，最优的eval loss不是在train loss 3.25 epoch最低点这里出现的，而是在2.25，出现的更早了。但这也不是坏事，说明模型有非常快的收敛速度。")]),t._v(" "),a("p",[t._v("同样的我把baseline也调整为4 eval per epoch，结果的对比如下图所示")]),t._v(" "),a("h2",{attrs:{id:"其他尝试"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#其他尝试"}},[t._v("#")]),t._v(" 其他尝试")]),t._v(" "),a("h3",{attrs:{id:"deberta-base-512"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deberta-base-512"}},[t._v("#")]),t._v(" deberta base 512")]),t._v(" "),a("p",[t._v("似乎不work")]),t._v(" "),a("p",[t._v("长度增长可见有明显的问题，很可能是淹没了短句子的效果。")]),t._v(" "),a("p",[t._v("loss图像，train loss偏高，且更早的达到了过拟合。。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595261404163210.jpg",alt:""}})]),t._v(" "),a("h3",{attrs:{id:"deberta-large-384"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deberta-large-384"}},[t._v("#")]),t._v(" deberta large 384")]),t._v(" "),a("p",[t._v("没有得到更好的效果，loss下降变得困难，可能是因为搜索空间太大了。")]),t._v(" "),a("p",[t._v("训练loss偏高，甚至和上面的base512也有一定的差距。且过拟合发生的时间较早。猜测模型可能关注更深的信息，而针对本数据集没有那么多的信息要学习。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595262821585440.jpg",alt:""}})]),t._v(" "),a("h3",{attrs:{id:"deberta-base-360"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deberta-base-360"}},[t._v("#")]),t._v(" deberta base 360")]),t._v(" "),a("p",[t._v("两者几乎持平，说明长度变少并未变弱模型的效果。后面可以进一步尝试，继续减少长度。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595267143843442.jpg",alt:""}})]),t._v(" "),a("p",[t._v("eval loss最优大概减少了0.0003个点，继续来看一下train loss后半段")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595274436582224.jpg",alt:""}})]),t._v(" "),a("p",[t._v("max_len 360的train loss最低点比baseline更优，同时最优eval loss也是在这个点左右完成的。可见模型train loss下降的越快、更低，越能找到更真正的东西。train loss和eval loss是一致的")]),t._v(" "),a("p",[t._v("可参考的最优loss为 "),a("strong",[t._v("0.456~0.457")])]),t._v(" "),a("h3",{attrs:{id:"最后三层相加"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#最后三层相加"}},[t._v("#")]),t._v(" 最后三层相加")]),t._v(" "),a("ul",[a("li",[t._v("1.求平均")])]),t._v(" "),a("p",[t._v("这种办法效果会变得特别差，效果不好。")]),t._v(" "),a("ul",[a("li",[t._v("2.直接相加，但是权重等于变成了三倍")])]),t._v(" "),a("p",[t._v("同样的来看train loss后半段。")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16595288088231332.jpg",alt:""}})]),t._v(" "),a("p",[t._v("后三层相加的结果要稍微的差一些。与最后两层直接相加相比，没有达到更好的效果。可见，适合本数据集的层数大概在一层上下的差距。")]),t._v(" "),a("p",[t._v("同时，1）和2）相差悬殊，这让我想到了另一个提高模型的点的办法，那就是给后两层相加的模型添加一个可学习的权重。")]),t._v(" "),a("h3",{attrs:{id:"top-layer-reinitialization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#top-layer-reinitialization"}},[t._v("#")]),t._v(" top layer reinitialization")]),t._v(" "),a("p",[t._v("因为语言模型的浅层保存的是通用的特征，靠近输出的地方是更加 task specific特征。之前的任务保留的权重可能会对当前任务造成一些的限制")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16597132571626208.png",alt:""}})]),t._v(" "),a("p",[t._v("但是运行之后发现这么做反而是最差的，如图中v16两个曲线（红蓝）")]),t._v(" "),a("h3",{attrs:{id:"加入人工抽取的关键词"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#加入人工抽取的关键词"}},[t._v("#")]),t._v(" 加入人工抽取的关键词")]),t._v(" "),a("p",[t._v("有略微的提升，当然也可能是偶然出现的，提升不大。如果能像上次patent针对每个类别加入动态的文本比较好")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16597140998333988.jpg",alt:""}})]),t._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("you your they we i think but also these some many people because there are\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("p",[t._v("是我认为写的比较差的作文里常用的词汇")]),t._v(" "),a("h3",{attrs:{id:"textcnn"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#textcnn"}},[t._v("#")]),t._v(" TextCNN")]),t._v(" "),a("p",[t._v("闲暇时间的翻阅之后，我发现比较差的文章比较喜欢用一些短语。")]),t._v(" "),a("p",[t._v("对于短语的提取可以使用text Cnn来实现，在bert的最后一层加上。")]),t._v(" "),a("p",[t._v("那么是加全局还是仅在ShortSentence呢？可能各有优势")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("1.全局：增加文章整体分数判断的能力。但是局部分类可能不行。")])]),t._v(" "),a("li",[a("p",[t._v("2.ShortSentence")]),t._v(" "),a("p",[t._v("本次的任务是段文本分类，长文本作为上下文来使用。由于bert是微调的，输出位置的短文本位置保留了短文本这部分的信息，如果短文本需要一些额外信息，他可以自己去长文本里查询——如果这一点成立，那么不一定需要用text CNN，作用在局部的mean pooling也可以试一试。")])])]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16591082895515714.jpg",alt:""}})]),t._v(" "),a("h4",{attrs:{id:"部分作用的cnn技术上的实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#部分作用的cnn技术上的实现"}},[t._v("#")]),t._v(" 部分作用的cnn技术上的实现")]),t._v(" "),a("p",[t._v("为了验证上述的想法，自然是需要做实验，一个个尝试。")]),t._v(" "),a("p",[t._v("在预处理的时候计算mask，然后直接mask_fill作用于最后一层")]),t._v(" "),a("p",[a("img",{attrs:{src:"http://kuroweb.tk/picture/16591089156903596.jpg",alt:""}})])])}),[],!1,null,null,null);e.default=s.exports}}]);